{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd10b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984328a",
   "metadata": {},
   "source": [
    "- `torchvision.datasets` 에서 데이터 로드\n",
    "- 아래 링크에서 built-in datasets의 목록을 확인해 볼 수 있습니다.\n",
    "  - [PyTorch Built-in Datsets](https://pytorch.org/vision/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046aeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transform 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a2725",
   "metadata": {},
   "source": [
    "`Fashion MNIST` 내장 데이터셋을 로드하여 실습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa434082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(학습용) 데이터셋 로드\n",
    "train_data = datasets.FashionMNIST(root='data', \n",
    "                                   train=True,        # 학습용 데이터셋 설정(True)\n",
    "                                   download=True, \n",
    "                                   transform=transform                \n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d964a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(학습용) 데이터셋 로드\n",
    "test_data = datasets.FashionMNIST(root='data', \n",
    "                                  train=False,        # 검증용 데이터셋 설정(False)\n",
    "                                  download=True, \n",
    "                                  transform=transform\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bb61b",
   "metadata": {},
   "source": [
    "`FashionMNIST` 데이터셋 시각화\n",
    "\n",
    "- 총 10개의 카테고리로 구성되어 있으며, `Label`은 아래 코드에서 `labels_map`에 정의되어 있습니다.\n",
    "- 출처: [zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"t-shirt/top\",\n",
    "    1: \"trouser\",\n",
    "    2: \"pullover\",\n",
    "    3: \"dress\",\n",
    "    4: \"coat\",\n",
    "    5: \"sandal\",\n",
    "    6: \"shirt\",\n",
    "    7: \"sneaker\",\n",
    "    8: \"bag\",\n",
    "    9: \"ankle boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "cols, rows = 6, 5\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(torch.permute(img, (1, 2, 0)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726f4b1",
   "metadata": {},
   "source": [
    "## torch.utils.data.DataLoader\n",
    "\n",
    "`DataLoader`는 배치 구성과 shuffle등을 편하게 구성해 주는 util 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # batch_size 지정\n",
    "num_workers = 8 # Thread 숫자 지정 (병렬 처리에 활용할 쓰레드 숫자 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08219f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d11be",
   "metadata": {},
   "source": [
    "`train_loader`의 1개 배치의 shape 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 배치 추출 후 Image, label의 shape 출력\n",
    "img, lbl = next(iter(train_loader))\n",
    "img.shape, lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180f133",
   "metadata": {},
   "source": [
    "배치사이즈인 32가 가장 첫번째 dimension에 출력되고, 그 뒤로 채널, 세로, 가로 순서로 출력이 됩니다.\n",
    "\n",
    "즉, greyscale 의 `28 X 28` 이미지 `32장`이 1개의 배치로 구성이 되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8369f6",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d88005",
   "metadata": {},
   "source": [
    "CUDA 설정이 되어 있다면 `cuda`를! 그렇지 않다면 `cpu`로 학습합니다.\n",
    "\n",
    "(제 PC에는 GPU가 2대 있어서 `cuda:0`로 GPU 장비의 index를 지정해 주었습니다. 만약 다른 장비를 사용하고 싶다면 `cuda:1` 이런식으로 지정해 주면 됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device 설정 (cuda:0 혹은 cpu)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d3d4a",
   "metadata": {},
   "source": [
    "아래의 모델은 DNN으로 구성하였습니다. 추후, 모델 부분을 CNN이나 pre-trained model로 교체할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff786d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.output = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNModel() # Model 생성\n",
    "model.to(device)   # device 에 로드 (cpu or cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82586144",
   "metadata": {},
   "source": [
    "## 훈련(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for img, lbl in prograss_bar:\n",
    "        # image, label 데이터를 device에 올립니다.\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(img)\n",
    "        \n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, lbl)\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
    "        pred = output.argmax(axis=1)\n",
    "\n",
    "        # 정답 개수를 카운트 합니다.\n",
    "        corr += (lbl == pred).sum().item()\n",
    "        \n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * img.size(0)\n",
    "        \n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4275f37",
   "metadata": {},
   "source": [
    "## 평가(Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for img, lbl in data_loader:\n",
    "            # device에 데이터를 올립니다.\n",
    "            img, lbl = img.to(device), lbl.to(device)\n",
    "            \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(img)\n",
    "            \n",
    "            # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
    "            pred = output.argmax(axis=1)\n",
    "            \n",
    "            # 정답 개수를 카운트 합니다.\n",
    "            corr += (lbl == pred).sum().item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, lbl).item() * img.size(0)\n",
    "        \n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac24e4f",
   "metadata": {},
   "source": [
    "## 모델 훈련(training) & 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 20\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(model, test_loader, loss_fn, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'DNNModel.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ee1de",
   "metadata": {},
   "source": [
    "## 저장한 가중치 로드 후 검증 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191eaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 저장한 가중치를 로드합니다.\n",
    "model.load_state_dict(torch.load('DNNModel.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1db76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n",
    "final_loss, final_acc = model_evaluate(model, test_loader, loss_fn, device)\n",
    "print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
