{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd10b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ced26",
   "metadata": {},
   "source": [
    "`torchvision`의 `Image Transform` 에 대하여 생소하다면 **다음의 링크를 참고**해 주시기 바랍니다.\n",
    "\n",
    "- [torchvision의 transform으로 이미지 정규화하기(평균, 표준편차를 계산하여 적용](https://teddylee777.github.io/pytorch/torchvision-transform)\n",
    "- [PyTorch 이미지 데이터셋(Image Dataset) 구성에 관한 거의 모든 것!](https://teddylee777.github.io/pytorch/dataset-dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec7d0d",
   "metadata": {},
   "source": [
    "`rps` 데이터셋을 다운로드 받아서 `tmp` 폴더에 압축을 풀어 줍니다.\n",
    "\n",
    "- `rps` 데이터셋은 **가위바위보 이미지 데이터셋** 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddeb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터셋 다운로드\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# 데이터셋을 다운로드 합니다.\n",
    "# 다운로드 후 tmp 폴더에 압축을 해제 합니다.\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\"\n",
    "urllib.request.urlretrieve(url, \"rps.zip\")\n",
    "local_zip = \"rps.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"tmp/\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a2725",
   "metadata": {},
   "source": [
    "`rps` 데이터셋을 시각화 하기 위하여 임시 `DataLoader`를 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# 이미지 폴더로부터 데이터를 로드합니다.\n",
    "dataset = ImageFolder(root='tmp/rps',                   # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                      ]))\n",
    "\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=True,\n",
    "                         num_workers=8\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFolder로부터 로드한 dataset의 클래스를 확인합니다.\n",
    "# 총 3개의 클래스로 구성되었음을 확인할 수 있습니다(paper, rock, scissors)\n",
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 배치를 추출합니다.\n",
    "images, labels = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 shape을 확인합니다. 300 X 300 RGB 이미지 임을 확인합니다.\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bb61b",
   "metadata": {},
   "source": [
    "`rps` 데이터셋 시각화\n",
    "\n",
    "- 총 3개의 class(가위/바위/보)로 구성된 사진 파일입니다.\n",
    "- 출처: [Laurence Moroney Dataset](http://laurencemoroney.com/rock-paper-scissors-dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ImageFolder의 속성 값인 class_to_idx를 할당\n",
    "labels_map = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "figure = plt.figure(figsize=(12, 8))\n",
    "cols, rows = 8, 4\n",
    "\n",
    "# 이미지를 출력합니다. RGB 이미지로 구성되어 있습니다.\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(images), size=(1,)).item()\n",
    "    img, label = images[sample_idx], labels[sample_idx].item()\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    # 본래 이미지의 shape은 (3, 300, 300) 입니다.\n",
    "    # 이를 imshow() 함수로 이미지 시각화 하기 위하여 (300, 300, 3)으로 shape 변경을 한 후 시각화합니다.\n",
    "    plt.imshow(torch.permute(img, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f94bb",
   "metadata": {},
   "source": [
    "## Image Augmentation 적용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc2d5c",
   "metadata": {},
   "source": [
    "`Image Augmentation`을 적용 합니다.\n",
    "\n",
    "- [PyTorch Image Augmentation 도큐먼트](https://pytorch.org/vision/stable/transforms.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b694687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transform을 지정합니다.\n",
    "image_transform = transforms.Compose([\n",
    "    # Resize (300 X 300) -> (224, 224) 크기 조정\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomHorizontalFlip(0.5),  # 50% 확률로 Horizontal Flip\n",
    "    transforms.ToTensor(),                 # Tensor 변환 (정규화)\n",
    "    #     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더로부터 데이터를 로드합니다.\n",
    "dataset = ImageFolder(root='tmp/rps',            # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
    "                      transform=image_transform)  # Image Augmentation 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6190f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation 이 적용된 DataLoader를 로드 합니다.\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=True,\n",
    "                         num_workers=8\n",
    "                         )\n",
    "\n",
    "# 1개의 배치를 추출합니다.\n",
    "images, labels = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b02756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFolder의 속성 값인 class_to_idx를 할당\n",
    "labels_map = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "figure = plt.figure(figsize=(12, 8))\n",
    "cols, rows = 8, 4\n",
    "\n",
    "# 이미지를 출력합니다. RGB 이미지로 구성되어 있습니다.\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(images), size=(1,)).item()\n",
    "    img, label = images[sample_idx], labels[sample_idx].item()\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    # 본래 이미지의 shape은 (3, 300, 300) 입니다.\n",
    "    # 이를 imshow() 함수로 이미지 시각화 하기 위하여 (300, 300, 3)으로 shape 변경을 한 후 시각화합니다.\n",
    "    plt.imshow(torch.permute(img, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d839e98",
   "metadata": {},
   "source": [
    "## train / validation 데이터셋 split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a234962",
   "metadata": {},
   "source": [
    "현재 `rps`에 하나의 데이터셋으로 구성된 Image 파일을 2개의 데이터셋(train/test)으로 분할하도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "ratio = 0.8  # 학습셋(train set)의 비율을 설정합니다.\n",
    "\n",
    "train_size = int(ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "print(f'total: {len(dataset)}\\ntrain_size: {train_size}\\ntest_size: {test_size}')\n",
    "\n",
    "# random_split으로 8:2의 비율로 train / test 세트를 분할합니다.\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2de821",
   "metadata": {},
   "source": [
    "## torch.utils.data.DataLoader\n",
    "\n",
    "`DataLoader`는 배치 구성과 shuffle등을 편하게 구성해 주는 util 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # batch_size 지정\n",
    "num_workers = 8  # Thread 숫자 지정 (병렬 처리에 활용할 쓰레드 숫자 지정)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers\n",
    "                          )\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=num_workers\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548cd025",
   "metadata": {},
   "source": [
    "`train_loader`의 1개 배치의 shape 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31cda9",
   "metadata": {},
   "source": [
    "배치사이즈인 32가 가장 첫번째 dimension에 출력되고, 그 뒤로 채널(3), 세로(224px), 가로(224px) 순서로 출력이 됩니다.\n",
    "\n",
    "즉, `224 X 224` RGB 컬러 이미지 `32장`이 1개의 배치로 구성이 되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 이미지의 shape를 확인합니다.\n",
    "# 224 X 224 RGB 이미지가 잘 로드 되었음을 확인합니다.\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8369f6",
   "metadata": {},
   "source": [
    "## 모델 정의\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d88005",
   "metadata": {},
   "source": [
    "CUDA 설정이 되어 있다면 `cuda`를! 그렇지 않다면 `cpu`로 학습합니다.\n",
    "\n",
    "(제 PC에는 GPU가 2대 있어서 `cuda:0`로 GPU 장비의 index를 지정해 주었습니다. 만약 다른 장비를 사용하고 싶다면 `cuda:1` 이런식으로 지정해 주면 됩니다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device 설정 (cuda:0 혹은 cpu)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d3d4a",
   "metadata": {},
   "source": [
    "아래의 모델은 DNN으로 구성하였습니다. 추후, 모델 부분을 CNN이나 pre-trained model로 교체할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff786d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Linear(7*7*128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()  # Model 생성\n",
    "model.to(device)   # device 에 로드 (cpu or cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a2ca18",
   "metadata": {},
   "source": [
    "`torchsummary`의 `summary`로 `CNNModel`의 구조와 paramter 수를 요약 출력 합니다.\n",
    "\n",
    "- 설치되어 있지 않다면 `pip install torchsummary`로 설치할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82586144",
   "metadata": {},
   "source": [
    "## 훈련(Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "\n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "\n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader)\n",
    "\n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for img, lbl in prograss_bar:\n",
    "        # image, label 데이터를 device에 올립니다.\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "\n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(img)\n",
    "\n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, lbl)\n",
    "\n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "\n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "\n",
    "        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
    "        pred = output.argmax(axis=1)\n",
    "\n",
    "        # 정답 개수를 카운트 합니다.\n",
    "        corr += (lbl == pred).sum().item()\n",
    "\n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * img.size(0)\n",
    "\n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "\n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4275f37",
   "metadata": {},
   "source": [
    "## 평가(Evaluate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "\n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for img, lbl in data_loader:\n",
    "            # device에 데이터를 올립니다.\n",
    "            img, lbl = img.to(device), lbl.to(device)\n",
    "\n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(img)\n",
    "\n",
    "            # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
    "            pred = output.argmax(axis=1)\n",
    "\n",
    "            # 정답 개수를 카운트 합니다.\n",
    "            corr += (lbl == pred).sum().item()\n",
    "\n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, lbl).item() * img.size(0)\n",
    "\n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "\n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac24e4f",
   "metadata": {},
   "source": [
    "## 모델 훈련(training) & 검증\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 10\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(\n",
    "        model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(\n",
    "            f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'CNNModel.pth')\n",
    "\n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ee1de",
   "metadata": {},
   "source": [
    "## 저장한 가중치 로드 후 검증 성능 측정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191eaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 저장한 가중치를 로드합니다.\n",
    "model.load_state_dict(torch.load(\"CNNModel.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1db76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n",
    "final_loss, final_acc = model_evaluate(model, test_loader, loss_fn, device)\n",
    "print(\n",
    "    f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
