{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd10b24",
      "metadata": {
        "id": "0bd10b24"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504ced26",
      "metadata": {
        "id": "504ced26"
      },
      "source": [
        "`torchvision`의 `Image Transform` 에 대하여 생소하다면 **다음의 링크를 참고**해 주시기 바랍니다.\n",
        "\n",
        "- [torchvision의 transform으로 이미지 정규화하기(평균, 표준편차를 계산하여 적용)](https://teddylee777.github.io/pytorch/torchvision-transform)\n",
        "- [PyTorch 이미지 데이터셋(Image Dataset) 구성에 관한 거의 모든 것!](https://teddylee777.github.io/pytorch/dataset-dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beec7d0d",
      "metadata": {
        "id": "beec7d0d"
      },
      "source": [
        "`개와 고양이` 데이터셋을 다운로드 받아서 `tmp` 폴더에 압축을 풀어 줍니다.\n",
        "\n",
        "[데이터셋 출처: 캐글, 마이크로소프트](https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ddeb61c",
      "metadata": {
        "id": "1ddeb61c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "if not os.path.exists(\"competition.py\"):\n",
        "    url = \"https://link.teddynote.com/COMPT\"\n",
        "    file_name = \"competition.py\"\n",
        "    response = requests.get(url)\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6s-jFRWLGrCM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s-jFRWLGrCM",
        "outputId": "aa55a512-9592-41e3-b7b2-7c40b1627c5d"
      },
      "outputs": [],
      "source": [
        "import competition\n",
        "\n",
        "# 파일 다운로드\n",
        "competition.download_competition_files(\n",
        "    f\"https://link.teddynote.com/CATSDOGS\", use_competition_url=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d51e25",
      "metadata": {
        "id": "e8d51e25"
      },
      "source": [
        "하단의 `code snippets`는 corrupted 된 이미지를 확인하고 제거하기 위한 코드 입니다. `Cats vs Dogs`데이터셋에도 원인 모를 이유 때문에 이미지 데이터가 corrupt된 파일이 2개가 존재합니다. 이렇게 corrupt 된 이미지를 `DataLoader`로 로드시 에러가 발생하기 때문에 전처리 때 미리 제거하도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0a2725",
      "metadata": {
        "id": "1d0a2725"
      },
      "source": [
        "`개와 고양이` 데이터셋을 시각화 하기 위하여 임시 `DataLoader`를 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c50d83e",
      "metadata": {
        "id": "4c50d83e"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# 이미지 폴더로부터 데이터를 로드합니다.\n",
        "dataset = ImageFolder(\n",
        "    root=\"data/images\",  # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            # 개와 고양이 사진 파일의 크기가 다르므로, Resize로 맞춰줍니다.\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b0b0ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5b0b0ff",
        "outputId": "897a0e08-69c8-4032-cc88-6de87a9523b4"
      },
      "outputs": [],
      "source": [
        "# ImageFolder로부터 로드한 dataset의 클래스를 확인합니다.\n",
        "# 총 2개의 클래스로 구성되었음을 확인할 수 있습니다(cats, dogs)\n",
        "dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0737bb3d",
      "metadata": {
        "id": "0737bb3d"
      },
      "outputs": [],
      "source": [
        "# 1개의 배치를 추출합니다.\n",
        "images, labels = next(iter(data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845b9943",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "845b9943",
        "outputId": "a672b5e3-da28-47f6-8371-b82fb18a5a3a"
      },
      "outputs": [],
      "source": [
        "# 이미지의 shape을 확인합니다. 224 X 224 RGB 이미지 임을 확인합니다.\n",
        "images[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8bb61b",
      "metadata": {
        "id": "9e8bb61b"
      },
      "source": [
        "`개와 고양이` 데이터셋 시각화\n",
        "\n",
        "- 총 2개의 class(강아지/고양이)로 구성된 사진 파일입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1695f09d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "1695f09d",
        "outputId": "76a4b80e-e916-447a-ce5e-d456b959cd93"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "# 한 배치의 이미지 시각화 함수 (사이즈 조정 포함)\n",
        "\n",
        "\n",
        "def imshow(img, labels, classes):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    plt.figure(figsize=(20, 20))  # 여기에서 플롯의 크기를 조정\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # 이미지마다 클래스 레이블을 타이틀로 표시\n",
        "    for i, label in enumerate(labels):\n",
        "        x = (i % 8) * (img.shape[1] / 8) + (img.shape[1] / 16)\n",
        "        y = (i // 8) * (img.shape[0] / 4) + 10  # 4 rows\n",
        "        plt.text(\n",
        "            x,\n",
        "            y,\n",
        "            classes[label],\n",
        "            ha=\"center\",\n",
        "            va=\"top\",\n",
        "            color=\"white\",\n",
        "            fontsize=12,\n",
        "            backgroundcolor=\"black\",\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 데이터 로더에서 한 배치 가져오기\n",
        "dataiter = iter(data_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 이미지 그리드 만들기\n",
        "img_grid = torchvision.utils.make_grid(images, nrow=8)  # 8개의 이미지를 한 줄에 표시\n",
        "\n",
        "# 이미지와 레이블 시각화\n",
        "imshow(img_grid, labels, dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d839e98",
      "metadata": {
        "id": "4d839e98"
      },
      "source": [
        "## train / validation 데이터셋 split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a234962",
      "metadata": {
        "id": "0a234962"
      },
      "source": [
        "현재 `cats and dogs`데이터셋에 하나의 데이터셋으로 구성된 Image 파일을 2개의 데이터셋(train/test)으로 분할하도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13f94bb",
      "metadata": {
        "id": "c13f94bb"
      },
      "source": [
        "## Image Augmentation 적용\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdc2d5c",
      "metadata": {
        "id": "5bdc2d5c"
      },
      "source": [
        "`Image Augmentation`을 적용 합니다.\n",
        "\n",
        "- [PyTorch Image Augmentation 도큐먼트](https://pytorch.org/vision/stable/transforms.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b694687",
      "metadata": {
        "id": "0b694687"
      },
      "outputs": [],
      "source": [
        "# Image Transform을 지정합니다.\n",
        "image_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),  # (224, 224) 이미지 크기 조정\n",
        "        transforms.RandomHorizontalFlip(0.5),  # 50% 확률로 Horizontal Flip\n",
        "        transforms.ToTensor(),  # Tensor 변환\n",
        "        #     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # 이미지 정규화\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc74d1b1",
      "metadata": {
        "id": "bc74d1b1"
      },
      "outputs": [],
      "source": [
        "# 이미지 폴더로부터 데이터를 로드합니다.\n",
        "dataset = ImageFolder(\n",
        "    root=\"data/images\",  # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
        "    transform=image_transform,\n",
        ")  # Image Augmentation 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6190f8",
      "metadata": {
        "id": "ae6190f8"
      },
      "outputs": [],
      "source": [
        "# Image Augmentation 이 적용된 DataLoader를 로드 합니다.\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8)\n",
        "\n",
        "# 1개의 배치를 추출합니다.\n",
        "images, labels = next(iter(data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b02756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "88b02756",
        "outputId": "e111eb6a-5c5d-47ff-e360-7bdd10caca71"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "# 한 배치의 이미지 시각화 함수 (사이즈 조정 포함)\n",
        "\n",
        "\n",
        "def imshow(img, labels, classes):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    plt.figure(figsize=(20, 20))  # 여기에서 플롯의 크기를 조정\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # 이미지마다 클래스 레이블을 타이틀로 표시\n",
        "    for i, label in enumerate(labels):\n",
        "        x = (i % 8) * (img.shape[1] / 8) + (img.shape[1] / 16)\n",
        "        y = (i // 8) * (img.shape[0] / 4) + 10  # 4 rows\n",
        "        plt.text(\n",
        "            x,\n",
        "            y,\n",
        "            classes[label],\n",
        "            ha=\"center\",\n",
        "            va=\"top\",\n",
        "            color=\"white\",\n",
        "            fontsize=12,\n",
        "            backgroundcolor=\"black\",\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 데이터 로더에서 한 배치 가져오기\n",
        "dataiter = iter(data_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 이미지 그리드 만들기\n",
        "img_grid = torchvision.utils.make_grid(images, nrow=8)  # 8개의 이미지를 한 줄에 표시\n",
        "\n",
        "# 이미지와 레이블 시각화\n",
        "imshow(img_grid, labels, dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05dd3181",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05dd3181",
        "outputId": "3b9d6238-b614-464f-abcc-87dd3a5ecf2b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "ratio = 0.8  # 학습셋(train set)의 비율을 설정합니다.\n",
        "\n",
        "train_size = int(ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "print(f\"total: {len(dataset)}\\ntrain_size: {train_size}\\ntest_size: {test_size}\")\n",
        "\n",
        "# random_split으로 8:2의 비율로 train / test 세트를 분할합니다.\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2de821",
      "metadata": {
        "id": "7a2de821"
      },
      "source": [
        "## torch.utils.data.DataLoader\n",
        "\n",
        "`DataLoader`는 배치 구성과 shuffle등을 편하게 구성해 주는 util 입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba61b2b7",
      "metadata": {
        "id": "ba61b2b7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32  # batch_size 지정\n",
        "num_workers = 8  # Thread 숫자 지정 (병렬 처리에 활용할 쓰레드 숫자 지정)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548cd025",
      "metadata": {
        "id": "548cd025"
      },
      "source": [
        "`train_loader`의 1개 배치의 shape 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4b882f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b4b882f",
        "outputId": "a524d168-ae49-4ede-838f-982441d63a10"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "images.shape, labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee31cda9",
      "metadata": {
        "id": "ee31cda9"
      },
      "source": [
        "배치사이즈인 32가 가장 첫번째 dimension에 출력되고, 그 뒤로 채널(3), 세로(224px), 가로(224px) 순서로 출력이 됩니다.\n",
        "\n",
        "즉, `224 X 224` RGB 컬러 이미지 `32장`이 1개의 배치로 구성이 되어 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20d3ecf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f20d3ecf",
        "outputId": "b2558d94-3cc9-4b07-b3d0-cbb3d7988c03"
      },
      "outputs": [],
      "source": [
        "# 1개의 이미지의 shape를 확인합니다.\n",
        "# 224 X 224 RGB 이미지가 잘 로드 되었음을 확인합니다.\n",
        "images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8679a47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8679a47",
        "outputId": "c20dcbe6-6169-496a-ac18-b159e1afd5c4"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b8369f6",
      "metadata": {
        "id": "7b8369f6"
      },
      "source": [
        "## pre-trained 모델 로드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d88005",
      "metadata": {
        "id": "f7d88005"
      },
      "source": [
        "CUDA 설정이 되어 있다면 `cuda`를! 그렇지 않다면 `cpu`로 학습합니다.\n",
        "\n",
        "(제 PC에는 GPU가 2대 있어서 `cuda:0`로 GPU 장비의 index를 지정해 주었습니다. 만약 다른 장비를 사용하고 싶다면 `cuda:1` 이런식으로 지정해 주면 됩니다)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25cb458b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25cb458b",
        "outputId": "026bd9a9-8c19-4c91-c33f-c1220e3a5908"
      },
      "outputs": [],
      "source": [
        "# CUDA 사용 가능 여부 확인\n",
        "if torch.backends.mps.is_built():\n",
        "    # mac os mps 지원 체크\n",
        "    device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
        "else:\n",
        "    # cuda 사용 가능한지 체크\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89d3d4a",
      "metadata": {
        "id": "f89d3d4a"
      },
      "source": [
        "**pre-trained model**을 fine tuning 하여 Image Classification을 구현하도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb3e28b",
      "metadata": {
        "id": "6cb3e28b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models  # pretrained 모델을 가져오기 위한 import\n",
        "\n",
        "# VGG16 모델 생성\n",
        "# weights=True 로 설정, weights=False로 설정되었을 경우 가중치는 가져오지 않습니다.\n",
        "model = models.vgg16(weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d92169a4",
      "metadata": {
        "id": "d92169a4"
      },
      "source": [
        "그 밖의 활용 가능한 pretrained 모델\n",
        "\n",
        "- `models.alexnet(pregrained=True)` # AlexNet\n",
        "- `models.resnet18(pretrained=True)` # ResNet18\n",
        "- `models.inception_v3(pretrained=True)` # Inception_V3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11fbdfdb",
      "metadata": {
        "id": "11fbdfdb"
      },
      "outputs": [],
      "source": [
        "# 가중치를 Freeze 하여 학습시 업데이트가 일어나지 않도록 설정합니다.\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # 가중치 Freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45a4421",
      "metadata": {
        "id": "f45a4421"
      },
      "outputs": [],
      "source": [
        "# Fully-Connected Layer를 Sequential로 생성하여 VGG pretrained 모델의 'Classifier'에 연결합니다.\n",
        "fc = nn.Sequential(\n",
        "    # VGG16 모델의 features의 출력이 7X7, 512장 이기 때문에 in_features=7*7*512 로 설정합니다.\n",
        "    nn.Linear(7 * 7 * 512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(\n",
        "        64, 2\n",
        "    ),  # Cats vs Dogs 이진 분류이기 때문에 2로 out_features=2로 설정합니다.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95003c44",
      "metadata": {
        "id": "95003c44"
      },
      "outputs": [],
      "source": [
        "# Classifier에 FC layer 대입\n",
        "model.classifier = fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90ee384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b90ee384",
        "outputId": "e2b75281-54be-4d38-cfac-f2497ac3289e"
      },
      "outputs": [],
      "source": [
        "# Classifier의 requires_grad 확인\n",
        "for param in model.classifier.parameters():\n",
        "    print(param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de227ffc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de227ffc",
        "outputId": "9c5aa614-bf23-4676-884b-5d44b2e0562c"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "# 모델의 구조도 출력\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8b2270",
      "metadata": {
        "id": "0e8b2270"
      },
      "outputs": [],
      "source": [
        "# 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82586144",
      "metadata": {
        "id": "82586144"
      },
      "source": [
        "## 훈련(Train) & 평가(Evaluate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d229193f",
      "metadata": {
        "id": "d229193f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def fit(model, data_loader, loss_fn, optimizer, device, phase=\"train\"):\n",
        "    if phase == \"train\":\n",
        "        # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
        "        model.train()\n",
        "    else:\n",
        "        # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n",
        "        model.eval()\n",
        "\n",
        "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
        "    running_loss = 0\n",
        "    corr = 0\n",
        "\n",
        "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
        "    prograss_bar = tqdm(data_loader, leave=False)\n",
        "\n",
        "    # mini-batch 학습을 시작합니다.\n",
        "    for img, lbl in prograss_bar:\n",
        "        # image, label 데이터를 device에 올립니다.\n",
        "        img, lbl = img.to(device), lbl.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # 누적 Gradient를 초기화 합니다.\n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "\n",
        "            # Forward Propagation을 진행하여 결과를 얻습니다.\n",
        "            output = model(img)\n",
        "\n",
        "            # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
        "            loss = loss_fn(output, lbl)\n",
        "\n",
        "            if phase == \"train\":\n",
        "                # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
        "                loss.backward()\n",
        "\n",
        "                # 계산된 Gradient를 업데이트 합니다.\n",
        "                optimizer.step()\n",
        "\n",
        "        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
        "        pred = output.argmax(axis=1)\n",
        "\n",
        "        # 정답 개수를 카운트 합니다.\n",
        "        corr += (lbl == pred).sum().item()\n",
        "\n",
        "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
        "    acc = corr / len(data_loader.dataset)\n",
        "\n",
        "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
        "    # train_loss, train_acc\n",
        "    return running_loss / len(data_loader), acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac24e4f",
      "metadata": {
        "id": "bac24e4f"
      },
      "source": [
        "## 모델 훈련(training) & 검증\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9a7089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9a7089",
        "outputId": "d8699a3c-e75d-4f5c-cb7c-895caf05b68f"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# 최대 Epoch을 지정합니다.\n",
        "num_epochs = 5\n",
        "\n",
        "min_loss = np.inf\n",
        "\n",
        "STATE_DICT_PATH = \"VGG-Pretrained-Model.pth\"\n",
        "\n",
        "# Epoch 별 훈련 및 검증을 수행합니다.\n",
        "for epoch in range(num_epochs):\n",
        "    # Model Training\n",
        "    # 훈련 손실과 정확도를 반환 받습니다.\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = fit(\n",
        "        model, train_loader, loss_fn, optimizer, device, phase=\"train\"\n",
        "    )\n",
        "\n",
        "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
        "    val_loss, val_acc = fit(\n",
        "        model, test_loader, loss_fn, optimizer, device, phase=\"eval\"\n",
        "    )\n",
        "\n",
        "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
        "    if val_loss < min_loss:\n",
        "        print(\n",
        "            f\"[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!\"\n",
        "        )\n",
        "        min_loss = val_loss\n",
        "        torch.save(model.state_dict(), STATE_DICT_PATH)\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    # Epoch 별 결과를 출력합니다.\n",
        "    print(\n",
        "        f\"[Epoch{epoch+1:02d}] time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s \\t loss: {train_loss:.5f}, acc: {train_acc:.5f} | val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514ee1de",
      "metadata": {
        "id": "514ee1de"
      },
      "source": [
        "## 저장한 가중치 로드 후 검증 성능 측정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191eaf7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191eaf7b",
        "outputId": "5380ce10-14af-4547-ceed-39710e697ea6"
      },
      "outputs": [],
      "source": [
        "# 모델에 저장한 가중치를 로드합니다.\n",
        "model.load_state_dict(torch.load(STATE_DICT_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1db76e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1db76e",
        "outputId": "80d6515d-bf6c-4433-a552-35e10a3ea32a"
      },
      "outputs": [],
      "source": [
        "# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n",
        "final_loss, final_acc = fit(\n",
        "    model, test_loader, loss_fn, optimizer, device, phase=\"eval\"\n",
        ")\n",
        "print(\n",
        "    f\"\\nevaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
