{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54227daa",
   "metadata": {},
   "source": [
    "# 이미지 증강(Image Augmentation) 적용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d57e6d",
   "metadata": {},
   "source": [
    "## 샘플 데이터셋 다운로드\n",
    "\n",
    "- 본 튜토리얼 에서는 kaggle에 공개된 `cats and dogs` 데이터셋을 활용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError, ImageFile\n",
    "\n",
    "\n",
    "# 이미지 Validation을 수행하고 Validate 여부를 return 합니다.\n",
    "def validate_image(filepath):\n",
    "    # image extensions\n",
    "    image_extensions = ['.jpg', '.jpeg', '.jfif',\n",
    "                        '.pjpeg', '.pjp', '.png', '.avif', '.gif']\n",
    "    # 이미지 파일 확장자를 가진 경우\n",
    "    if any(filepath.endswith(s) for s in image_extensions):\n",
    "        try:\n",
    "            # PIL.Image로 이미지 데이터를 로드하려고 시도합니다.\n",
    "            img = Image.open(filepath).convert('RGB')\n",
    "            img.load()\n",
    "        except UnidentifiedImageError:  # corrupt 된 이미지는 해당 에러를 출력합니다.\n",
    "            print(f'Corrupted Image is found at: {filepath}')\n",
    "            return False\n",
    "        except (IOError, OSError):  # Truncated (잘린) 이미지에 대한 에러를 출력합니다.\n",
    "            print(f'Truncated Image is found at: {filepath}')\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        print(f'File is not an image: {filepath}')\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_dataset(download_url, folder, default_folder='tmp'):\n",
    "    # 데이터셋을 다운로드 합니다.\n",
    "    urllib.request.urlretrieve(download_url, 'datasets.zip')\n",
    "\n",
    "    # 다운로드 후 tmp 폴더에 압축을 해제 합니다.\n",
    "    local_zip = 'datasets.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall(f'{default_folder}/')\n",
    "    zip_ref.close()\n",
    "\n",
    "    # 잘린 이미지 Load 시 경고 출력 안함\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "    # image 데이터셋 root 폴더\n",
    "    root = f'{default_folder}/{folder}'\n",
    "\n",
    "    dirs = os.listdir(root)\n",
    "\n",
    "    for dir_ in dirs:\n",
    "        folder_path = os.path.join(root, dir_)\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        images = [os.path.join(folder_path, f) for f in files]\n",
    "        for img in images:\n",
    "            valid = validate_image(img)\n",
    "            if not valid:\n",
    "                # corrupted 된 이미지 제거\n",
    "                os.remove(img)\n",
    "\n",
    "    folders = glob.glob(f'{default_folder}/{folder}/*')\n",
    "    print(folders)\n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ac04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개, 고양이 데이터셋 다운로드를 받습니다.\n",
    "# 받은 데이터는 tmp/PetImages 폴더 안에 저장됩니다.\n",
    "# 중간에 Truncated 된 이미지가 존재합니다.\n",
    "download_dataset(\n",
    "    'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip', 'PetImages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362052a",
   "metadata": {},
   "source": [
    "## 학습에 활용할 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45997c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "torch.manual_seed(321)\n",
    "\n",
    "# 이미지 크기를 224 x 224 로 조정합니다\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452f10d",
   "metadata": {},
   "source": [
    "`torchvision.datasets.ImageFolder`\n",
    "\n",
    "- `root`: 이미지 폴더가 위치한 루트 폴더의 경로를 입력합니다.\n",
    "- `transform`: 이미지 변형에 대한 함수를 입력합니다.\n",
    "- `traget_transform`: `target` 값에 대한 변형하는 함수를 입력합니다. 원핫인코딩을 적용할 수 있습니다.\n",
    "- `loader`: 이미지 로더 함수를 적용할 수 있습니다.\n",
    "- `is_valid_file`: 이미지의 corrupt여부를 체크할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fba4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더로부터 데이터를 로드합니다.\n",
    "original_dataset = ImageFolder(root='tmp/PetImages',                            # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
    "                               transform=transforms.Compose([                   # Resize 후 정규화(0~1)를 수행합니다.\n",
    "                                   # 개와 고양이 사진 파일의 크기가 다르므로, Resize로 맞춰줍니다.\n",
    "                                   transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                   transforms.ToTensor()\n",
    "                               ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더를 생성합니다.\n",
    "original_loader = DataLoader(original_dataset,  # 이전에 생성한 original_dataset를 로드 합니다.\n",
    "                             batch_size=16,    # 배치사이즈\n",
    "                             shuffle=False,     # 셔플 여부\n",
    "                             num_workers=1\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 배치를 추출합니다.\n",
    "original_images, labels = next(iter(original_loader))\n",
    "\n",
    "# 이미지의 shape을 확인합니다. 224 X 224 RGB 이미지 임을 확인합니다.\n",
    "# (batch_size, channel, height, width)\n",
    "original_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1485e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "# permute로 이미지의 shape를 다음과 같이 변경합니다\n",
    "# (height, width, channel)\n",
    "plt.imshow(original_images[0].permute(1, 2, 0))\n",
    "plt.grid(False)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763da61",
   "metadata": {},
   "source": [
    "개와 고양이 이미지 데이터셋의 원본 사진을 시각화 합니다. 처음 3장의 이미지만 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1)\n",
    "fig.set_size_inches(4, 6)\n",
    "\n",
    "for idx in range(3):\n",
    "    axes[idx].imshow(original_images[idx].permute(1, 2, 0))\n",
    "    axes[idx].set_axis_off()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d1027",
   "metadata": {},
   "source": [
    "이미지 변환기(Image Transforms)는 [공식도큐먼트 링크](https://pytorch.org/vision/stable/transforms.html)에서 세부 함수의 인자(parameter)와 사용 예시를 확인할 수 있습니다. 아래는 몇 가지 함수를 적용해보고 원본 이미지와 비교하여 시각화한 결과입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8138131",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    # 개와 고양이 사진 파일의 크기가 다르므로, Resize로 맞춰줍니다.\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((IMAGE_SIZE, IMAGE_SIZE)),  # 중앙 Crop\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 이미지 폴더로부터 데이터를 로드합니다.\n",
    "transform_dataset = ImageFolder(root='tmp/PetImages',                  # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
    "                                transform=image_transform)\n",
    "\n",
    "# 데이터 로더를 생성합니다.\n",
    "transform_loader = DataLoader(transform_dataset,  # 이전에 생성한 transform_dataset를 적용합니다.\n",
    "                              batch_size=16,     # 배치사이즈\n",
    "                              shuffle=False,      # 셔플 여부\n",
    "                              num_workers=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a361dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_images, labels = next(iter(transform_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2)\n",
    "fig.set_size_inches(4, 6)\n",
    "\n",
    "for idx in range(3):\n",
    "    axes[idx, 0].imshow(original_images[idx].permute(1, 2, 0))\n",
    "    axes[idx, 0].set_axis_off()\n",
    "    axes[idx, 0].set_title(\"Original\")\n",
    "    axes[idx, 1].imshow(transform_images[idx].permute(1, 2, 0))\n",
    "    axes[idx, 1].set_axis_off()\n",
    "    axes[idx, 1].set_title(\"CenterCrop\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader(transform):\n",
    "    # 이미지 폴더로부터 데이터를 로드합니다.\n",
    "    transform_dataset = ImageFolder(root='tmp/PetImages',  # 다운로드 받은 폴더의 root 경로를 지정합니다.\n",
    "                                    transform=transform)\n",
    "\n",
    "    # 데이터 로더를 생성합니다.\n",
    "    transform_loader = DataLoader(transform_dataset,      # 이전에 생성한 transform_dataset를 적용합니다.\n",
    "                                  batch_size=16,          # 배치사이즈\n",
    "                                  shuffle=False,          # 셔플 여부\n",
    "                                  num_workers=1\n",
    "                                  )\n",
    "\n",
    "    transform_images, labels = next(iter(transform_loader))\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2)\n",
    "    fig.set_size_inches(4, 6)\n",
    "\n",
    "    for idx in range(3):\n",
    "        axes[idx, 0].imshow(original_images[idx].permute(1, 2, 0))\n",
    "        axes[idx, 0].set_axis_off()\n",
    "        axes[idx, 0].set_title('Original')\n",
    "        axes[idx, 1].imshow(transform_images[idx].permute(1, 2, 0))\n",
    "        axes[idx, 1].set_axis_off()\n",
    "        axes[idx, 1].set_title('Transformed')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca1048",
   "metadata": {},
   "source": [
    "`ColorJitter`\n",
    "\n",
    "- `brightness`: 밝기 조절 (0~1)\n",
    "- `contrast`: 대비 조절 (0~1)\n",
    "- `saturation`: 채도 조절 (0~1)\n",
    "- `hue`: 휴 조절 (-0.5~0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca796c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # ColorJitter 적용\n",
    "    transforms.ColorJitter(brightness=(0.5, 0.9),\n",
    "                           contrast=(0.4, 0.8),\n",
    "                           saturation=(0.7, 0.9),\n",
    "                           hue=(-0.2, 0.2),\n",
    "                           ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65aa7c",
   "metadata": {},
   "source": [
    "`RandomHorizontalFlip(p=0.5)`\n",
    "\n",
    "- Horizontal Flip의 확률을 조절합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13318332",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # RandomHorizontalFlip 적용\n",
    "    transforms.RandomHorizontalFlip(p=0.8),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a63d7",
   "metadata": {},
   "source": [
    "`GaussianBlur(kernel_size, sigma=(0.1, 2.0))`\n",
    "\n",
    "- `kernel_size`: 가우시안 커널의 크기\n",
    "- `sigma`: 커널의 Standard Deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4110e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # GaussianBlur 적용\n",
    "    transforms.GaussianBlur(kernel_size=(19, 19), sigma=(1.0, 2.0)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f24f6",
   "metadata": {},
   "source": [
    "`RandomRotation(degrees, interpolation=InterpolationMode.NEAREST, expand=False, center=None, fill=0)`\n",
    "\n",
    "- `degrees`: 로테이션에 적용할 각도 (min, max)\n",
    "- `interpolation`: 기본 값(`InterpolationMode.NEAREST`). `InterpolationMode.BILINEAR` 추가 적용 가능\n",
    "- `fill`: 기본 값(0). 픽셀 값으로 채울 값 지정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1914c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # RandomRotation 적용\n",
    "    transforms.RandomRotation(\n",
    "        degrees=(-30, 30), interpolation=transforms.InterpolationMode.BILINEAR, fill=0),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c40670",
   "metadata": {},
   "source": [
    "`Pad(padding, fill=0, padding_mode='constant')`\n",
    "\n",
    "- `padding`: 단일 값으로 지정시 left, right, top, bottom에 동일하게 패딩 적용. 2개 지정시 left/right, top/bottom 순차 적용. 4개 적용시 left, top, right, bottom 순서대로 적용\n",
    "- `fill`: 단일 값으로 지정시 해당 값으로 픽셀 값으로 채움. tuple 형태로 3개 지정시 RGB 채널에 순차 적용.\n",
    "- `padding_mode`: 기본 값은 `constant`. `edge`, `reflect`, `symmetric`으로 변경 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # Pad 적용\n",
    "    transforms.Pad(padding=(100, 50, 100, 200),\n",
    "                   fill=255, padding_mode='symmetric'),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e538d05",
   "metadata": {},
   "source": [
    "`RandomAdjustSharpness(sharpness_factor, p=0.5)`\n",
    "\n",
    "- `sharpness_factor`: 선명도를 얼마나 조절할 것인가. 0은 흐릿한 이미지를 제공하고 1은 원본 이미지를 제공하는 반면 2는 선명도를 2배 증가시킵니다.\n",
    "- `p`: 선명도(sharpness) 적용 확률\n",
    "\n",
    "주어진 확률로 이미지의 선명도를 임의로 조정합니다. 이미지가 토치 텐서인 경우, […, 1 또는 3, H, W] 모양을 가질 것으로 예상되며, 여기서 ...는 임의의 수의 선행 차원을 의미합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be93f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # RandomAdjustSharpness 적용\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=0.1, p=0.9),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a3abd",
   "metadata": {},
   "source": [
    "**데이터로부터 학습 증강 전략**에 기반한 자동증강 데이터 증강 방법.\n",
    "\n",
    "`AutoAugment(policy: AutoAugmentPolicy = AutoAugmentPolicy.IMAGENET, interpolation: InterpolationMode = InterpolationMode.NEAREST, fill: Optional[List[float]] = None)`\n",
    "\n",
    "- `policy`: torchvision.transforms에 의해 정의된 원하는 정책 열거형입니다. 기본값은 `transforms.autoaugment.AutoAugmentPolicy`입니다(ImageNet).\n",
    "- `interpolation`: torchvision.transforms에 의해 정의된 원하는 보간 모드. 기본 값(`InterpolationMode.NEAREST`). `InterpolationMode.BILINEAR` 추가 적용 가능.\n",
    "- `fill`: 변환된 이미지 외부 영역의 픽셀 채우기 값.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # AutoAugment 적용\n",
    "    transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET,\n",
    "                           interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "create_loader(image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f99056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
