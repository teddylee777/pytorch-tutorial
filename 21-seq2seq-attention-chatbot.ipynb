{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Unicode warning 제거 (폰트 관련 경고메시지)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = \"NanumGothic\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'ChatbotData.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = df[\"Q\"]\n",
    "answer = df[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e6744",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ce925",
   "metadata": {},
   "source": [
    "### 1-1. 한글 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdebcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거\n",
    "korean_pattern = r\"[^ ?,.!A-Za-z0-9가-힣+]\"\n",
    "\n",
    "# 패턴 컴파일\n",
    "normalizer = re.compile(korean_pattern)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"수정 전: {question[10]}\")\n",
    "print(f'수정 후: {normalizer.sub(\"\", question[10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c918464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"수정 전: {answer[10]}\")\n",
    "print(f'수정 후: {normalizer.sub(\"\", answer[10])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentence):\n",
    "    return normalizer.sub(\"\", sentence)\n",
    "\n",
    "\n",
    "normalize(question[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d1d77",
   "metadata": {},
   "source": [
    "### 1-2. 한글 형태소 분석기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003483bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "# 형태소 분석기\n",
    "mecab = Mecab()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab\n",
    "mecab.morphs(normalize(question[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt\n",
    "okt.morphs(normalize(answer[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 전처리를 함수화\n",
    "def clean_text(sentence, tagger):\n",
    "    sentence = normalize(sentence)\n",
    "    sentence = tagger.morphs(sentence)\n",
    "    sentence = \" \".join(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글\n",
    "clean_text(question[10], okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea788a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어\n",
    "clean_text(answer[10], okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(question), len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce95632",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [clean_text(sent, okt) for sent in question.values[:1000]]\n",
    "answers = [clean_text(sent, okt) for sent in answer.values[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bfa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73844c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa240d8",
   "metadata": {},
   "source": [
    "### 1-3. 단어 사전 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6887a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVocab():\n",
    "    def __init__(self):\n",
    "        SOS_TOKEN = 0\n",
    "        EOS_TOKEN = 1\n",
    "        UNKNOWN_TOKEN = 2\n",
    "\n",
    "        self.unknown_token = UNKNOWN_TOKEN\n",
    "\n",
    "        # 각 토큰 별 word count\n",
    "        self.word2count = {}\n",
    "\n",
    "        # word -> idx\n",
    "        self.word2index = {\n",
    "            '<SOS>': SOS_TOKEN,\n",
    "            '<EOS>': EOS_TOKEN,\n",
    "            '<UKN>': UNKNOWN_TOKEN,\n",
    "        }\n",
    "\n",
    "        # idx -> word\n",
    "        self.index2word = {\n",
    "            SOS_TOKEN: '<SOS>',\n",
    "            EOS_TOKEN: '<EOS>',\n",
    "            UNKNOWN_TOKEN: '<UKN>',\n",
    "        }\n",
    "\n",
    "        # total word counts\n",
    "        self.n_words = 3  # SOS, EOS, UNKNOWN 포함\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        if word in self.word2index:\n",
    "            return self.word2index[word]\n",
    "        else:\n",
    "            return self.unknown_token\n",
    "\n",
    "    def index_to_word(self, idx):\n",
    "        return self.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60766793",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa82bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"원문: {questions[10]}\")\n",
    "wordvocab = WordVocab()\n",
    "wordvocab.add_sentence(questions[10])\n",
    "print(\"===\" * 10)\n",
    "print(\"단어사전\")\n",
    "print(wordvocab.word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa67a9",
   "metadata": {},
   "source": [
    "### 1-4. 전처리 프로세스를 클래스화\n",
    "\n",
    "- 데이터를 로드하고, 정규화 및 전처리, 토큰화를 진행합니다.\n",
    "- 단어 사전을 생성하고 이에 따라, 시퀀스로 변환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "\n",
    "class QADataset():\n",
    "    def __init__(self, csv_path, min_length=3, max_length=25):\n",
    "        data_dir = 'data'\n",
    "\n",
    "        # TOKEN 정의\n",
    "        self.SOS_TOKEN = 0  # SOS 토큰\n",
    "        self.EOS_TOKEN = 1  # EOS 토큰\n",
    "\n",
    "        self.tagger = Okt()   # 형태소 분석기\n",
    "        self.max_length = max_length  # 한 문장의 최대 길이 지정\n",
    "\n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(os.path.join(data_dir, csv_path))\n",
    "\n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.compile(korean_pattern)\n",
    "\n",
    "        # src: 질의, tgt: 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "\n",
    "        # 단어 사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            src = row['Q']\n",
    "            tgt = row['A']\n",
    "\n",
    "            # 한글 전처리\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "\n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)\n",
    "\n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocab = wordvocab\n",
    "\n",
    "    def normalize(self, sentence):\n",
    "        # 정규표현식에 따른 한글 정규화\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "\n",
    "    def clean_text(self, sentence):\n",
    "        # 한글 정규화\n",
    "        sentence = self.normalize(sentence)\n",
    "        # 형태소 처리\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "\n",
    "    def texts_to_sequences(self, sentence):\n",
    "        # 문장 -> 시퀀스로 변환\n",
    "        sequences = [self.wordvocab.word_to_index(w) for w in sentence.split()]\n",
    "        # 문장 최대 길이 -1 까지 슬라이싱\n",
    "        sequences = sequences[:self.max_length-1]\n",
    "        # 맨 마지막에 EOS TOKEN 추가\n",
    "        sequences.append(self.EOS_TOKEN)\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        # 시퀀스 -> 문장으로 변환\n",
    "        sentences = [self.wordvocab.index_to_word(s.item()) for s in sequences]\n",
    "        return ' '.join(sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.srcs[idx]\n",
    "        inputs_sequences = self.texts_to_sequences(inputs)\n",
    "\n",
    "        outputs = self.tgts[idx]\n",
    "        outputs_sequences = self.texts_to_sequences(outputs)\n",
    "\n",
    "        return torch.tensor(inputs_sequences).view(-1, 1), torch.tensor(outputs_sequences).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aabadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 문장의 최대 단어길이를 25로 설정\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "dataset = QADataset(\"ChatbotData.csv\", min_length=3, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafba0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번 index 데이터셋 조회\n",
    "# 결과: x(입력 데이터), y(출력 데이터)\n",
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[3]\n",
    "\n",
    "# 시퀀스를 문장으로 변환\n",
    "print(dataset.sequences_to_texts(x))\n",
    "print(dataset.sequences_to_texts(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f6490",
   "metadata": {},
   "source": [
    "## 2. Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54945a",
   "metadata": {},
   "source": [
    "![](https://tutorials.pytorch.kr/_images/encoder-network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70706f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # 단어 사전의 개수 지정\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 임베딩 레이어 정의 (number of vocabs, embedding dimension)\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        # GRU (embedding dimension)\n",
    "        self.gru = nn.GRU(embedding_dim,\n",
    "                          hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          bidirectional=False,\n",
    "                          batch_first=True,\n",
    "                          )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x).view(1, 1, -1)\n",
    "        # x: (1, 1, embedding_dim)\n",
    "        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        # output: (batch_size, sequence_length, hidden_size(32) x bidirectional(1))\n",
    "        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, device):\n",
    "        # hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32)) 로 초기화\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9b4a0",
   "metadata": {},
   "source": [
    "- Embedding Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8af4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 추출\n",
    "x, y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e645c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20  # 임베딩 차원\n",
    "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
    "\n",
    "embedded = embedding(x[0])\n",
    "\n",
    "print(x.shape)\n",
    "print(embedded.view(1, 1, -1).shape)\n",
    "# input:  (sequence_length, 1)\n",
    "# output: (1, 1, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0f2cf",
   "metadata": {},
   "source": [
    "- GRU Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20  # 임베딩 차원\n",
    "hidden_size = 32   # GRU hidden_size\n",
    "\n",
    "gru = nn.GRU(embedding_dim,\n",
    "             hidden_size,\n",
    "             num_layers=1,\n",
    "             bidirectional=False)\n",
    "\n",
    "o, h = gru(embedded.view(1, 1, -1))\n",
    "\n",
    "print(o.shape)\n",
    "# output      : (batch_size, sequence_length, hidden_size(32) x bidirectional(1))\n",
    "print(h.shape)\n",
    "# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e3cee",
   "metadata": {},
   "source": [
    "- Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VOCABS = dataset.wordvocab.n_words\n",
    "print(f\"number of vocabs: {NUM_VOCABS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d30d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 정의\n",
    "encoder = Encoder(NUM_VOCABS,\n",
    "                  hidden_size=32,\n",
    "                  embedding_dim=20,\n",
    "                  num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4443b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder hidden_state 초기화\n",
    "encoder.init_hidden(device=device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18357f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder에 x 통과 후 output, hidden_size 의 shape 확인\n",
    "encoder_out, encoder_hidden = encoder(\n",
    "    x[0], torch.zeros_like(encoder.init_hidden(device='cpu')))\n",
    "\n",
    "print(encoder_out.shape)\n",
    "print(encoder_hidden.shape)\n",
    "# output      : (batch_size, sequence_length, hidden_size(32) x bidirectional(1))\n",
    "# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786ad2b",
   "metadata": {},
   "source": [
    "## 3. Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9a0fa",
   "metadata": {},
   "source": [
    "![](https://tutorials.pytorch.kr/_images/decoder-network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 단어사전 개수\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim,\n",
    "                          hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          bidirectional=False)\n",
    "        # 최종 출력은 단어사전의 개수\n",
    "        self.fc = nn.Linear(hidden_size, num_vocabs)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        x = self.embedding(x)  # (H): 1개의 word에 대한 h\n",
    "        x = x.view(1, 1, -1)  # (1, 1, H) 로 변환\n",
    "        embedded = F.relu()\n",
    "        output, hidden = self.gru(embedded, hidden_state)\n",
    "        # (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n",
    "        output = self.fc(output.squeeze(0))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7a7ee",
   "metadata": {},
   "source": [
    "- Embedding Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.abs(torch.randn(size=(10, 1)).long())\n",
    "print(x.shape)\n",
    "# (디코더의 sequence_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20  # 임베딩 차원\n",
    "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
    "\n",
    "embedded = embedding(x[0])\n",
    "# 디코더의 1개 토큰에 대한 임베딩 차원\n",
    "# (1, embedding_dim)\n",
    "print(embedded.shape)\n",
    "embedded = embedded.view(1, 1, -1)\n",
    "# (1, 1, embedding_dim)\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a104b396",
   "metadata": {},
   "source": [
    "- GRU Layer의 입/출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20  # 임베딩 차원\n",
    "hidden_size = 32\n",
    "\n",
    "gru = nn.GRU(embedding_dim,\n",
    "             hidden_size,\n",
    "             num_layers=1,\n",
    "             bidirectional=False)\n",
    "\n",
    "decoder_out, decoder_hidden = gru(embedded)\n",
    "\n",
    "print(decoder_out.shape)\n",
    "# decoder_out: (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n",
    "print(decoder_hidden.shape)\n",
    "# decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aadd48",
   "metadata": {},
   "source": [
    "- 출력층(FC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(32, NUM_VOCABS)  # 출력은 단어사전의 개수로 가정\n",
    "\n",
    "output = fc(decoder_out[0])\n",
    "\n",
    "print(decoder_out[0].shape)\n",
    "print(output.shape)\n",
    "# input : (batch_size, hidden_size)\n",
    "# output: (batch_size, output dimension(number of vocabs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73eaf27",
   "metadata": {},
   "source": [
    "## 4. Attention 이 적용된 Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e078e",
   "metadata": {},
   "source": [
    "![](https://tutorials.pytorch.kr/_images/attention-decoder-network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df12bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.attn = nn.Linear(hidden_size + embedding_dim, max_length)\n",
    "        self.attn_combine = nn.Linear(hidden_size + embedding_dim, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, num_vocabs)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        # x: (1, 1) 1개의 토큰\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        # embedded: (1, 1, 1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # embedded[0]: (1, embedding_dim)\n",
    "        # hidden[0]: (1, hidden_size)\n",
    "        attn_in = torch.cat((embedded[0], hidden[0]), 1)\n",
    "        # attn_in: (1, embedding_dim + hidden_size)\n",
    "\n",
    "        attn = self.attn(attn_in)\n",
    "        # attn: (1, max_length)\n",
    "\n",
    "        attn_weights = F.softmax(attn)\n",
    "        # attn_weights: (1, max_length)\n",
    "\n",
    "        # (1, 1, max_length), (1, max_length, hidden_size)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(\n",
    "            0), encoder_outputs.unsqueeze(0))\n",
    "        # attn_applied: (1, 1, hidden_size)\n",
    "\n",
    "        # embedded[0]: (1, embedding_dim)\n",
    "        # attn_applied[0]: (1, hidden_size)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        # output: (1, embedding_dim + hidden_size)\n",
    "\n",
    "        output = self.attn_combine(output)\n",
    "        # output: (1, hidden_size)\n",
    "        output = output.unsqueeze(0)\n",
    "        # output: (1, 1, hidden_size)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        # output: (1, 1, hidden_size)\n",
    "\n",
    "        # output: (1, 1, hidden_size)\n",
    "        # hidden: (1, 1, hidden_size)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output: (1, 1, hidden_size)\n",
    "        # hidden: (1, 1, hidden_size)\n",
    "\n",
    "        # output[0]: (1, hidden_size)\n",
    "        output = self.out(output[0])\n",
    "        # output: (1, number of vocabs)\n",
    "\n",
    "        # output[0]: (number of vocabs)\n",
    "        # hidden: (1, 1, hidden_size)\n",
    "        # attn_weights: (1, max_length)\n",
    "        return output[0], hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, device):\n",
    "        # (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 문장의 길이가 12 단어라고 가정한 경우\n",
    "x = torch.abs(torch.randn(size=(12, 1)).long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a51c6",
   "metadata": {},
   "source": [
    "- 디코더의 단어 1개에 대한 Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8aa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20\n",
    "embedding = nn.Embedding(wordvocab.n_words, embedding_dim)\n",
    "\n",
    "# Decoder의 단어 1개: x[0]를 입력으로 가짐\n",
    "embedded = embedding(x[0])\n",
    "print(embedded.shape)\n",
    "# (1, 20)\n",
    "\n",
    "embedded = embedded.view(1, 1, -1)\n",
    "# (1, 1, 20)\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72578f",
   "metadata": {},
   "source": [
    "- 드롭아웃 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout 적용\n",
    "dropout = nn.Dropout(0.1)\n",
    "embedded = dropout(embedded)\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc583126",
   "metadata": {},
   "source": [
    "- 디코더의 첫 번째 단어는 Encoder `hidden_state`를 사용\n",
    "- 두 번째 단어부터는 이전 단계의 Decoder `hidden_state`를 사용\n",
    "- 디코드의 현재 입력 Embedding + (Encoder `hidden_state` or Decoder 이전 단계의 `hidden_state`)를 concat\n",
    "- 결과는 `(1, E + H)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 단어는 encoder_hidden 사용, 두 번째 단어부터는 decoder_hidden 사용\n",
    "# encoder_hidden.shape == decoder_hidden.shape 같아야 함\n",
    "# hidden.shape: (1, 1, H)\n",
    "hidden = encoder_hidden\n",
    "print(hidden[0].shape)\n",
    "print(embedded[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코드의 현재 입력 Embedding + (Encoder hidden_state or Decoder 이전 단계의 hidden_state)를 concat\n",
    "context = torch.cat((embedded[0], hidden[0]), 1)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b45648",
   "metadata": {},
   "source": [
    "- attention 생성\n",
    "- FC 레이어: (1, E+H) -> (1, MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1, E+H) -> (1, MAX_LENGTH)\n",
    "fc = nn.Linear(hidden_size + embedding_dim, MAX_LENGTH)\n",
    "attn = fc(context)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = F.softmax(attn, dim=1)\n",
    "# attn weights: (1, MAX_LENGTH)\n",
    "print(\"변경 전:\", attn_weights.shape)\n",
    "# (1, MAX_LENGTH) -> (1, 1, MAX_LENGTH)\n",
    "attn_weights = attn_weights.unsqueeze(0)\n",
    "print(\"변경 후:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder의 시퀀스 별 H가 모두 채워진 Matrix\n",
    "encoder_outputs = torch.zeros(MAX_LENGTH, hidden_size)\n",
    "# (MAX_LENGTH, H)\n",
    "print(\"변경 전:\", encoder_outputs.shape)\n",
    "encoder_outputs = encoder_outputs.unsqueeze(0)\n",
    "# (1, MAX_LENGTH, H)\n",
    "print(\"변경 후\", encoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec9d52f",
   "metadata": {},
   "source": [
    "- `attention weights`: **현재의 디코더 입력** (1개 단어)와 **이전 단계의 hidden_state** 사이에서 구한 **Energy**\n",
    "- `encoder outputs`: 인코더의 **전체 문장 출력** (MAX_LENGTH, hidden_size)로 이루어짐.\n",
    "- `attention weights` 와 `encoder outputs` 간의 Attention BMM을 산출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMM: (1, 1, MAX_LENGTH) x (1, MAX_LENGTH, H) => (1, 1, H)\n",
    "# BMM 적용 후: (1, 1, H)\n",
    "attn_applied = torch.bmm(attn_weights, encoder_outputs)\n",
    "attn_applied.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd58a07",
   "metadata": {},
   "source": [
    "- 디코더의 현재 입력 (1개 단어)와 Attention 값을 concat\n",
    "- (1, E) + (1, H) = (1, E+H)\n",
    "- FC: (1, E+H) -> (1, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "# (1, E+H)\n",
    "print(\"concat 결과 : \", output.shape)\n",
    "fc = nn.Linear(hidden_size + embedding_dim, hidden_size)\n",
    "output = fc(output)\n",
    "# (1, H)\n",
    "print(\"FC 통과 후   : \", output.shape)\n",
    "# GRU 입력으로 넣기 위하여 (1, H) -> (1, 1, H)\n",
    "output = output.unsqueeze(0)\n",
    "print(\"unsqueeze 후: \", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37543b1",
   "metadata": {},
   "source": [
    "- output을 ReLU 통과\n",
    "- GRU의 입력으로 output, hidden 주입\n",
    "- output: (1, 1, H), hidden: (1, 1, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = F.relu(output)\n",
    "gru = nn.GRU(hidden_size, hidden_size)\n",
    "output, hidden = gru(output, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3613f4",
   "metadata": {},
   "source": [
    "- output: (1, 1, 32) -> (1, 32)\n",
    "- output을 최종 출력으로 변경: (1, number of vocabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1, H) -> (1, number of vocabs)\n",
    "out = nn.Linear(hidden_size, dataset.wordvocab.n_words)\n",
    "decoder_out = out(output[0])\n",
    "# (1, number of vocabs)\n",
    "decoder_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9fa13",
   "metadata": {},
   "source": [
    "- attention 디코더 입출력 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장의 길이가 12 단어라고 가정한 경우\n",
    "# x: 12개의 토큰으로 이루어진 입력 문장이라고 가정\n",
    "x = torch.abs(torch.randn(size=(12, 1)).long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce93fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size)\n",
    "# (max_length, hidden_size)\n",
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1, 1, hidden_size)\n",
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62312eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention이 적용된 디코더 생성\n",
    "decoder = AttentionDecoder(num_vocabs=NUM_VOCABS,\n",
    "                           hidden_size=32,\n",
    "                           embedding_dim=20,\n",
    "                           dropout_p=0.1,\n",
    "                           max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[0]: 디코더의 입력으로 들어가는 1개 토큰\n",
    "decoder_out, decoder_hidden, attn_weights = decoder(\n",
    "    y[0], encoder_hidden, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_out: (number of vocabs)\n",
    "# decoder_hidden: (1, 1, hidden_size)\n",
    "# attn_weights: (1, max_length)\n",
    "decoder_out.shape, decoder_hidden.shape, attn_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f711ff",
   "metadata": {},
   "source": [
    "## 5. Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = dataset.SOS_TOKEN\n",
    "EOS_TOKEN = dataset.EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시 training loss 를 출력하기 위한 util 함수\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격에 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.title('Losses over training')\n",
    "    plt.show()\n",
    "\n",
    "# 훈련시 시간 출력을 위한 util 함수\n",
    "\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{int(m)}m {int(s)}s'\n",
    "\n",
    "# 훈련시 시간 출력을 위한 util 함수\n",
    "\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return f'{as_minutes(s)} (remaining: {as_minutes(rs)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2766687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, device, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
    "\n",
    "    # Encoder의 hidden_state 초기화\n",
    "    encoder_hidden = encoder.init_hidden(device=device)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # input_length: 입력 문장의 길이\n",
    "    # target_length: 출력 문장의 길이\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # Encoder의 출력 결과를 담을 tensor\n",
    "    # (문장의 max_length, encoder의 hidden_size)\n",
    "    encoder_outputs = torch.zeros(\n",
    "        max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        # Encoder의 출력을 encoder_outputs[ei] 에 저장\n",
    "        # encoder_output[0, 0]: (hidden_size,)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # Decoder의 첫 토큰은 SOS_TOKEN\n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "\n",
    "    # Encoder의 마지막 hidden state를 Decoder의 초기 hidden state로 지정\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # teacher forcing 적용 여부 확률로 결정\n",
    "    # teacher forcing 이란: 정답치를 다음 RNN Cell의 입력으로 넣어주는 경우. 수렴속도가 빠를 수 있으나, 불안정할 수 있음\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        # loss 계산\n",
    "        loss += criterion(decoder_output.view(1, -1), target_tensor[di])\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # teacher forcing 적용: 정답 값 입력\n",
    "            decoder_input = target_tensor[di]\n",
    "        else:\n",
    "            # 확률, 인덱스\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # 다음 입력으로 주입할 디코더 최종 토큰 결정\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "        # EOS_TOKEN 이면 종료\n",
    "        if decoder_input.item() == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40936ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterations(encoder, decoder, n_iters, dataset, device, print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0  # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 랜덤 샘플링된 데이터셋 생성\n",
    "    training_pairs = [dataset[random.randint(\n",
    "        0, len(dataset)-1)] for i in range(n_iters)]\n",
    "\n",
    "    # Loss Function 정의\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # n_iters 만큼 training 시작\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # 문장 pair\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        # 입력 문장\n",
    "        input_tensor = training_pair[0]\n",
    "        # 출력 문장\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        # 훈련\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, criterion, device)\n",
    "\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        # print_every 마다 loss 출력\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(\n",
    "                f'{time_since(start, iter/n_iters)} iter: {iter} ({iter/n_iters*100:.1f}%), loss: {print_loss_avg:.4f}')\n",
    "\n",
    "        # plot_every 마다 loss 시각화\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc03a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter 정의\n",
    "NUM_VOCABS = dataset.wordvocab.n_words\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDING_DIM = 256\n",
    "DROPOUT_P = 0.1\n",
    "\n",
    "# Encoder 정의\n",
    "encoder = Encoder(NUM_VOCABS,\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  embedding_dim=EMBEDDING_DIM,\n",
    "                  num_layers=1)\n",
    "\n",
    "# Attention 이 적용된 Decoder 정의\n",
    "decoder = AttentionDecoder(num_vocabs=NUM_VOCABS,\n",
    "                           hidden_size=HIDDEN_SIZE,\n",
    "                           embedding_dim=EMBEDDING_DIM,\n",
    "                           dropout_p=DROPOUT_P,\n",
    "                           max_length=MAX_LENGTH)\n",
    "\n",
    "# encoder, decoder 생성 및 device 지정\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6732cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(encoder, decoder, 100000, dataset, device, print_every=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aadd4e",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d54fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, dataset, device, max_length=MAX_LENGTH):\n",
    "    # Eval 모드 설정\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size(0)\n",
    "        # Encoder의 hidden state 초기화\n",
    "        encoder_hidden = encoder.init_hidden(device=device)\n",
    "\n",
    "        # encoder_outputs는 Encoder를 통과한 문장의 출력\n",
    "        # (max_length, hidden_size)\n",
    "        encoder_outputs = torch.zeros(\n",
    "            max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        # Encoder 에 입력 문자 주입 후 encoder_outputs 생성\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        # Decoder의 첫 번째 입력으로 SOS_TOKEN 입력(SOS_TOKEN=0)\n",
    "        decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "        # Decoder의 첫 번째 hidden state는 Encoder의 마지막 hidden state 사용\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # 1개의 Decoder 입력 토큰을 통과\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # Attention 시각화를 위한 tensor 저장\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "\n",
    "            # 출력 토큰 예측\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "            # EOS_TOKEN이면 종료\n",
    "            if topi.item() == dataset.EOS_TOKEN:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                # 출력 문장에 토큰 시퀀스(index)를 단어(word)로 변환한 후 저장\n",
    "                decoded_words.append(\n",
    "                    dataset.wordvocab.index_to_word(topi.item()))\n",
    "\n",
    "            # decoder_input은 다음 토큰 예측시 입력 값\n",
    "            # decoder_input: (hidden_size,)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "\n",
    "def evaluate_randomly(encoder, decoder, dataset, device, n=10):\n",
    "    for i in range(n):\n",
    "        # 랜덤 샘플링\n",
    "        x, y = random.choice(dataset)\n",
    "        # 입력 문장, 출력 문장 (Ground Truth)\n",
    "        print('>', dataset.sequences_to_texts(x))\n",
    "        print('=', dataset.sequences_to_texts(y))\n",
    "\n",
    "        # 예측\n",
    "        output_words, attentions = evaluate(\n",
    "            encoder, decoder, x.to(device), dataset, device)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "\n",
    "        # 예측 문장 출력\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 샘플링 된 데이터 evaluate\n",
    "evaluate_randomly(encoder, decoder, dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5daef7",
   "metadata": {},
   "source": [
    "## 7. Attention 가중치 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Weights를 활용한 시각화\n",
    "output_words, attentions = evaluate(\n",
    "    encoder, decoder, dataset[2][0].to(device), dataset, device)\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화를 위한 함수\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # colorbar로 그림 설정\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # 매 틱마다 라벨 보여주기\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_and_show_attention(encoder, decoder, input_sentence, dataset, device):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, decoder, input_sentence.to(device), dataset, device)\n",
    "    input_sentence = dataset.sequences_to_texts(input_sentence)\n",
    "    output_words = ' '.join(output_words)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', output_words)\n",
    "    show_attention(input_sentence, output_words.split(), attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(encoder, decoder, dataset[2][0], dataset, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
