{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d3737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# 1,000 단위 표기\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "# Unicode warning 제거 (폰트 관련 경고메시지)\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "# 그래프 출력 사이즈 설정\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data 경로 설정\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# 시드설정\n",
    "SEED = 123\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(SEED)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0009ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-17</th>\n",
       "      <td>465.864</td>\n",
       "      <td>468.174</td>\n",
       "      <td>452.422</td>\n",
       "      <td>457.334</td>\n",
       "      <td>457.334</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-18</th>\n",
       "      <td>456.860</td>\n",
       "      <td>456.860</td>\n",
       "      <td>413.104</td>\n",
       "      <td>424.440</td>\n",
       "      <td>424.440</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-19</th>\n",
       "      <td>424.103</td>\n",
       "      <td>427.835</td>\n",
       "      <td>384.532</td>\n",
       "      <td>394.796</td>\n",
       "      <td>394.796</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-20</th>\n",
       "      <td>394.673</td>\n",
       "      <td>423.296</td>\n",
       "      <td>389.883</td>\n",
       "      <td>408.904</td>\n",
       "      <td>408.904</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-21</th>\n",
       "      <td>408.085</td>\n",
       "      <td>412.426</td>\n",
       "      <td>393.181</td>\n",
       "      <td>398.821</td>\n",
       "      <td>398.821</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Adj Close    Volume\n",
       "Date                                                           \n",
       "2014-09-17 465.864 468.174 452.422 457.334    457.334  21056800\n",
       "2014-09-18 456.860 456.860 413.104 424.440    424.440  34483200\n",
       "2014-09-19 424.103 427.835 384.532 394.796    394.796  37919700\n",
       "2014-09-20 394.673 423.296 389.883 408.904    408.904  36863600\n",
       "2014-09-21 408.085 412.426 393.181 398.821    398.821  26580100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FinanceDataReader as fdr\n",
    "\n",
    "df = fdr.DataReader('BTC/USD')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a379e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2014-09-17      457.334\n",
       "2014-09-18      424.440\n",
       "2014-09-19      394.796\n",
       "2014-09-20      408.904\n",
       "2014-09-21      398.821\n",
       "                ...    \n",
       "2023-06-29   30,445.352\n",
       "2023-06-30   30,477.252\n",
       "2023-07-01   30,590.078\n",
       "2023-07-02   30,620.770\n",
       "2023-07-03   30,988.707\n",
       "Name: Close, Length: 3212, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1ea404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00414359],\n",
       "       [0.00365546],\n",
       "       [0.00321557],\n",
       "       [0.00342492],\n",
       "       [0.0032753 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "series = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "series[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23a30b",
   "metadata": {},
   "source": [
    "## Windowed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262bff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PREDICTIONS = 25\n",
    "WINDOW_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391c4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(series, window_size=WINDOW_SIZE, n_predictions=N_PREDICTIONS):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for i in range(len(series) - window_size - n_predictions +1):\n",
    "        Xs.append(series[i:i+window_size])\n",
    "        Ys.append(series[i+window_size: i+window_size+n_predictions])\n",
    "    return np.array(Xs), np.array(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2869e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "Xs, Ys = make_dataset(series.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b25e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3163, 25, 1), (3163, 25))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = np.expand_dims(Xs, -1)\n",
    "Xs.shape, Ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5dcb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 200\n",
    "\n",
    "x_train, y_train = Xs[:-n_splits], Ys[:-n_splits]\n",
    "x_valid, y_valid = Xs[-n_splits:], Ys[-n_splits:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478333fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2963, 25, 1), (2963, 25))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f699b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 25, 1), (200, 25))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999b772e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45067765],\n",
       "       [0.44966215],\n",
       "       [0.44655879],\n",
       "       [0.45274727],\n",
       "       [0.44381524],\n",
       "       [0.4491441 ],\n",
       "       [0.44961748],\n",
       "       [0.45129174],\n",
       "       [0.45174718],\n",
       "       [0.45720711]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff08bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40087701],\n",
       "       [0.39856144],\n",
       "       [0.40393552],\n",
       "       [0.39552768],\n",
       "       [0.39638717],\n",
       "       [0.39994054],\n",
       "       [0.39436453],\n",
       "       [0.39581064],\n",
       "       [0.40136719],\n",
       "       [0.38814676],\n",
       "       [0.39024487],\n",
       "       [0.39385206],\n",
       "       [0.39606404],\n",
       "       [0.41412779],\n",
       "       [0.40908597],\n",
       "       [0.40843994],\n",
       "       [0.40127714],\n",
       "       [0.3953461 ],\n",
       "       [0.40172131],\n",
       "       [0.39913243],\n",
       "       [0.39978444],\n",
       "       [0.37961832],\n",
       "       [0.40156095],\n",
       "       [0.38831266],\n",
       "       [0.39071987]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9df9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39030672, 0.38097081, 0.38229043, 0.38173147, 0.38197229,\n",
       "       0.37018912, 0.3768923 , 0.38803761, 0.39075636, 0.38816745,\n",
       "       0.39580696, 0.41771654, 0.44294047, 0.44123373, 0.45285566,\n",
       "       0.45067765, 0.44966215, 0.44655879, 0.45274727, 0.44381524,\n",
       "       0.4491441 , 0.44961748, 0.45129174, 0.45174718, 0.45720711])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9813b8",
   "metadata": {},
   "source": [
    "## Tensor DataSet 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5609aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor(x, device):\n",
    "    return torch.FloatTensor(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7888074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device 설정 (cuda 혹은 cpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b2c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = make_tensor(x_train, device=device)\n",
    "y_train = make_tensor(y_train, device=device)\n",
    "x_valid = make_tensor(x_valid, device=device)\n",
    "y_valid = make_tensor(y_valid, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa75152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid_ds = torch.utils.data.TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1f09a",
   "metadata": {},
   "source": [
    "## DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96950fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_ds, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_ds, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c293705",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8dcbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "706bb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, bidirectional=True, drop_prob=0.1):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, output_size)\n",
    "        \n",
    "    def init_hidden_and_cell_state(self, batch_size, device):\n",
    "        self.hidden_and_cell = (\n",
    "            torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size).to(device),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (h, c) = self.lstm(x, self.hidden_and_cell)\n",
    "        h = output[:, -1, :]\n",
    "        o = self.dropout(h)\n",
    "        o = self.fc(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d28bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 1,\n",
    "    'hidden_size': 64, \n",
    "    'num_layers': 2, \n",
    "    'bidirectional': True,\n",
    "    'output_size': N_PREDICTIONS, \n",
    "    \n",
    "}\n",
    "\n",
    "model = BaseModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bde6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.to(device), y.to(device)\n",
    "\n",
    "model = model.to(device)\n",
    "model.init_hidden_and_cell_state(batch_size, device)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d463180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d90944",
   "metadata": {},
   "source": [
    "## 손실함수 & 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0251347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.HuberLoss()\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fc320",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad4400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "#     prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for idx, (xs, ys) in enumerate(data_loader):\n",
    "        # txt, lbl 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "        xs = xs.to(device)\n",
    "        ys = ys.to(device)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # LSTM Weight 초기화\n",
    "        model.init_hidden_and_cell_state(len(xs), device)\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(xs)\n",
    "        \n",
    "        # 손실함수에 output, lbl 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, ys)\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # batch 별 loss 계산하여 누적합을 구합니다.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 프로그레스바에 학습 상황 업데이트\n",
    "#         prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}\")\n",
    "        \n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss\n",
    "    return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ad435d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for xs, ys in data_loader:\n",
    "            # txt, lbl 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "            xs = xs.to(device)\n",
    "            ys = ys.to(device)\n",
    "            \n",
    "            # LSTM Weight 초기화\n",
    "            model.init_hidden_and_cell_state(len(xs), device)\n",
    "    \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(xs)\n",
    "            \n",
    "            # 검증 손실을 구합니다.\n",
    "            loss = loss_fn(output, ys)\n",
    "            \n",
    "            # batch 별 loss 계산하여 누적합을 구합니다.\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d5042d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 0.02758. Saving Model!\n",
      "epoch 01, loss: 0.03576, val_loss: 0.02758\n",
      "[INFO] val_loss has been improved from 0.02758 to 0.01226. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.01226 to 0.00913. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00913 to 0.00589. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00589 to 0.00246. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00246 to 0.00079. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00079 to 0.00075. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00075 to 0.00065. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00065 to 0.00062. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00062 to 0.00061. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00061 to 0.00061. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00061 to 0.00058. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00058 to 0.00056. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00056 to 0.00055. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00055 to 0.00052. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00052 to 0.00052. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00052 to 0.00049. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00049 to 0.00048. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00048 to 0.00048. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00048 to 0.00047. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00047 to 0.00046. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00046 to 0.00046. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00046 to 0.00046. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00046 to 0.00046. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00046 to 0.00046. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00046 to 0.00045. Saving Model!\n",
      "[INFO] val_loss has been improved from 0.00045 to 0.00045. Saving Model!\n",
      "epoch 101, loss: 0.00149, val_loss: 0.00047\n",
      "[INFO] val_loss has been improved from 0.00045 to 0.00045. Saving Model!\n",
      "epoch 201, loss: 0.00121, val_loss: 0.00048\n",
      "epoch 301, loss: 0.00110, val_loss: 0.00047\n",
      "epoch 401, loss: 0.00105, val_loss: 0.00047\n",
      "epoch 501, loss: 0.00102, val_loss: 0.00048\n",
      "epoch 601, loss: 0.00098, val_loss: 0.00048\n",
      "epoch 701, loss: 0.00102, val_loss: 0.00048\n",
      "epoch 801, loss: 0.00097, val_loss: 0.00049\n",
      "epoch 901, loss: 0.00096, val_loss: 0.00050\n"
     ]
    }
   ],
   "source": [
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 1000\n",
    "\n",
    "# checkpoint로 저장할 모델의 이름을 정의 합니다.\n",
    "model_name = 'TimeSeries-LSTM'\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실을 반환 받습니다.\n",
    "    train_loss = model_train(model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    # 검증 손실을 반환 받습니다.\n",
    "    val_loss = model_evaluate(model, valid_loader, loss_fn, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, val_loss: {val_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e4341",
   "metadata": {},
   "source": [
    "## 저장한 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbacb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{model_name}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c2b39",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data = series[-WINDOW_SIZE:]\n",
    "last_data = torch.FloatTensor(last_data).to(device)\n",
    "last_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc92e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data = torch.unsqueeze(last_data, 0)#.unsqueeze(0)\n",
    "last_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323965b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(last_data)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a590273",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEXT_TIMESTEPS = 50\n",
    "N_ITER = NEXT_TIMESTEPS // WINDOW_SIZE\n",
    "\n",
    "model.eval()\n",
    "\n",
    "results = []\n",
    "inputs = torch.tensor(last_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(last_data)\n",
    "    for i in range(N_ITER):\n",
    "        model.init_hidden_and_cell_state(1, device)\n",
    "        output = model(inputs)\n",
    "        results.append(output)\n",
    "        inputs = torch.unsqueeze(output, -1)\n",
    "        \n",
    "results = torch.cat(results, axis=1).squeeze().detach().cpu().numpy()\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257a675",
   "metadata": {},
   "source": [
    "## 예측 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(scaler.inverse_transform(series[-NEXT_TIMESTEPS:]).flatten(), color='black', linestyle='dotted', label='real')\n",
    "ax.plot(scaler.inverse_transform(results.reshape(-1, 1)).flatten(), color='tomato', label='prediction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
