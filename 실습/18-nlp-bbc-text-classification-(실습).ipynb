{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc8feb3",
   "metadata": {},
   "source": [
    "## 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c39526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 시드설정\n",
    "SEED = 123\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744dbbce",
   "metadata": {},
   "source": [
    "## 샘플 예제파일 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "# bbc-text.csv 데이터셋 다운로드\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/bbc-text.csv'\n",
    "urllib.request.urlretrieve(url, 'bbc-text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ce279",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e335ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# 데이터프레임을 로드 합니다.\n",
    "df = pd.read_csv('bbc-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d2859",
   "metadata": {},
   "source": [
    "## 토큰화 (Word Tokenization)\n",
    "\n",
    "- get_tokenizer로 토크나이저 생성\n",
    "- `basic_english`, `spacy`, `revtok`, `subword` 등 지정이 가능하나, 몇몇 토크나이저는 추가 라이브러리 설치가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# 토큰 생성\n",
    "tokenizer = # 코드작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8f542",
   "metadata": {},
   "source": [
    "## 단어사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens(sentences):\n",
    "    for text in sentences:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29176448",
   "metadata": {},
   "source": [
    "`build_vocab_from_iterator` 를 활용하여 단어 사전을 생성합니다.\n",
    "\n",
    "- `min_freq`: 최소 빈도의 토큰의 개수를 입력합니다.\n",
    "- `max_tokens`: 최대 빈도 토큰의 수를 한정합니다. 빈도수 기준으로 산정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71928f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = # 코드작성\n",
    "vocab.set_default_index(vocab['<UNK>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade2e3e",
   "metadata": {},
   "source": [
    "## 단어사전의 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 단어사전의 개수 출력\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17a169",
   "metadata": {},
   "source": [
    "## 라벨 맵 생성 (문자 -> 숫자 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "{v:i for i, v in enumerate(df['category'].value_counts().keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'sport': 0, \n",
    "    'business': 1, \n",
    "    'politics': 2, \n",
    "    'tech': 3, \n",
    "    'entertainment': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea63497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_num'] = df['category'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a9cc8",
   "metadata": {},
   "source": [
    "## Dataset 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db988dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = # 코드작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d38128",
   "metadata": {},
   "source": [
    "## Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bff8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, tokenizer):\n",
    "        super().__init__()\n",
    "        # 코드작성\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return # 코드작성\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = # 코드작성\n",
    "        label = # 코드작성\n",
    "        return # 코드작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3251b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset 생성\n",
    "train_ds = # 코드작성\n",
    "valid_ds = # 코드작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 데이터 추출\n",
    "text, label = next(iter(train_ds))\n",
    "len(text), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a56d3",
   "metadata": {},
   "source": [
    "## DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed101327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881230a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch, max_sequence_length):\n",
    "    label_list, text_list = [], []\n",
    "    \n",
    "    for text, label in batch:\n",
    "        # 최대 문장길이를 넘어가는 단어는 제거합니다.\n",
    "        processed_text = # 코드작성\n",
    "        text_list.# 코드작성\n",
    "        label_list.# 코드작성\n",
    "    \n",
    "    label_list = # 코드작성\n",
    "    \n",
    "    # padding을 주어 짧은 문장에 대한 길이를 맞춥니다.\n",
    "    text_list = # 코드작성\n",
    "    \n",
    "    return # 코드작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 문장에 최대 포함하는 단어의 개수를 지정합니다. (예시. 200 단어)\n",
    "MAX_SEQUENCE_LENGTH = # 코드작성\n",
    "\n",
    "train_loader = # 코드작성\n",
    "\n",
    "valid_loader = # 코드작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "x.shape, y.shape\n",
    "# (batch_size, seq_length), (batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4112ba",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, num_classes, vocab_size, embedding_dim, hidden_size, num_layers, bidirectional=True, drop_prob=0.1):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.num_classes = # 코드작성\n",
    "        self.vocab_size = # 코드작성\n",
    "        self.embedding_dim = # 코드작성\n",
    "        self.hidden_size = # 코드작성\n",
    "        self.num_layers = # 코드작성\n",
    "        self.bidirectional = # 코드작성\n",
    "        \n",
    "        self.embedding = # 코드작성\n",
    "        \n",
    "        self.lstm = # 코드작성\n",
    "        \n",
    "        self.dropout = # 코드작성\n",
    "        \n",
    "        self.relu = # 코드작성\n",
    "        \n",
    "        self.fc = # 코드작성\n",
    "        self.output = # 코드작성\n",
    "        \n",
    "    def init_hidden_and_cell_state(self, batch_size, device):\n",
    "        # LSTM 입력시 초기 Cell 에 대한 가중치 초기화를 진행합니다.\n",
    "        # (num_layers*bidirectional, batch_size, hidden_size)\n",
    "        self.hidden_and_cell = (\n",
    "            torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size).to(device),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, (h, c) = self.lstm(x, self.hidden_and_cell)\n",
    "        # (batch_size, seq_length, hidden_size*bidirectional)\n",
    "        # last sequence 의 (batch_size, hidden_size*bidirectional)\n",
    "        h = output[:, -1, :]\n",
    "        o = self.dropout(h)\n",
    "        o = self.relu(self.fc(o))\n",
    "        o = self.dropout(o)\n",
    "        return self.output(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a2fa0",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_classes': # 코드작성, \n",
    "    'vocab_size': # 코드작성,\n",
    "    'embedding_dim': # 코드작성 \n",
    "    'hidden_size': # 코드작성\n",
    "    'num_layers': # 코드작성 \n",
    "    'bidirectional': # 코드작성\n",
    "}\n",
    "\n",
    "model = TextClassificationModel(**config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4816050",
   "metadata": {},
   "source": [
    "## 손실함수 및 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030efd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 정의: CrossEntropyLoss\n",
    "loss_fn = # 코드작성\n",
    "\n",
    "# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n",
    "optimizer = # 코드작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    counts = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for idx, (txt, lbl) in enumerate(prograss_bar):\n",
    "        # txt, lbl 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "        txt = txt.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # LSTM Weight 초기화\n",
    "        model.# 코드작성\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = # 코드작성\n",
    "        \n",
    "        # 손실함수에 output, lbl 값을 대입하여 손실을 계산합니다.\n",
    "        loss = # 코드작성\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.# 코드작성\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.# 코드작성\n",
    "        \n",
    "        # Probability Max index 를 구합니다.\n",
    "        output = output.# 코드작성\n",
    "        \n",
    "        # 정답 개수를 구합니다.\n",
    "        corr += (output == lbl).sum().item()\n",
    "        counts += len(lbl)\n",
    "        \n",
    "        # batch 별 loss 계산하여 누적합을 구합니다.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 프로그레스바에 학습 상황 업데이트\n",
    "        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n",
    "        \n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb57c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for txt, lbl in data_loader:\n",
    "            # txt, lbl 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "            txt = txt.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            \n",
    "            # LSTM Weight 초기화\n",
    "            model.# 코드작성\n",
    "    \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = # 코드작성\n",
    "            \n",
    "            # 검증 손실을 구합니다.\n",
    "            loss = # 코드작성\n",
    "            \n",
    "            # Probability Max index 를 구합니다.\n",
    "            output = output.# 코드작성\n",
    "            \n",
    "            # 정답 개수를 구합니다.\n",
    "            corr += (output == lbl).sum().item()\n",
    "            \n",
    "            # batch 별 loss 계산하여 누적합을 구합니다.\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 50\n",
    "\n",
    "# checkpoint로 저장할 모델의 이름을 정의 합니다.\n",
    "model_name = 'BBC-Text-CLF-LSTM'\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(model, valid_loader, loss_fn, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef40913c",
   "metadata": {},
   "source": [
    "## 저장한 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5473a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.# 코드작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d859e9",
   "metadata": {},
   "source": [
    "## 최종 검증 손실 및 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb76e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc = model_evaluate(model, valid_loader, loss_fn, device)\n",
    "    \n",
    "    print(f'loss: {val_loss:.5f}, accuracy: {val_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
